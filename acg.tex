\section{Abstract Categorial Grammars}
\label{sec:acg}

We present the grammatical framework in which we will develop our
system. Abstract categorial grammars are built upon two mathematical
structures, \emph{(higher-order) signatures} and \emph{lexicons}.

\subsection{Higher-Order Signatures}
\label{ssec:sig}

A \textbf{higher-order signature} is a set of elements that we call
\emph{constants}, each of which is associated with a type. Formally, it
is defined as a triple $\Sigma = \mathopen{<}A, C, \tau\mathclose{>}$,
where:
\begin{itemize}
  \item $C$ is the (finite) set of constants
  \item $A$ is a (finite) set of atomic types
  \item $\tau$ is the type-associating mapping from $C$ to
    $\mathcal{T}(A)$, the set of types built over $A$
\end{itemize}

In our case, $\mathcal{T}(A)$ is the implicative fragment of linear and
intuitionistic logic with $A$ being the atomic propositions. This means
that $\mathcal{T}(A)$ contains all the $a \in A$ and all the $\alpha \limp
\beta$ and $\alpha \to \beta$ for $\alpha, \beta \in \mathcal{T}(A)$.

A signature $\Sigma = \mathopen{<}A, C, \tau\mathclose{>}$, by itself,
already lets us define an interesting set of structures, that is the set
$\Lambda(\Sigma)$ of \emph{well-typed lambda terms} built upon the
signature $\Sigma$. The set of well-typed terms and their types are
established through the judgment schemas in Figure
\ref{fig:type-judgments}.

\begin{figure}
  \begin{prooftree}
    \AxiomC{$\emptyset; \Gamma_i \vdash_\Sigma c : \tau(c)$ (cons)}
  \end{prooftree}
  \begin{prooftree}
    \AxiomC{$(x : \alpha); \Gamma_i \vdash_\Sigma x : \alpha$ (l-var)}
  \end{prooftree}
  \begin{prooftree}
    \AxiomC{$\emptyset; (\Gamma_i, x : \alpha) \vdash_\Sigma x : \alpha$ (i-var)}
  \end{prooftree}
  \begin{prooftree}
    \AxiomC{$(\Gamma_l, x : \alpha); \Gamma_i \vdash_\Sigma t : \beta$}
    \RightLabel{(l-abs)}
    \UnaryInfC{$\Gamma_l; \Gamma_i \vdash_\Sigma \lambda^{\circ} x. t : \alpha \limp \beta$}
  \end{prooftree}
  \begin{prooftree}
    \AxiomC{$\Gamma_l; (\Gamma_i, x : \alpha) \vdash_\Sigma t : \beta$}
    \RightLabel{(i-abs)}
    \UnaryInfC{$\Gamma_l; \Gamma_i \vdash_\Sigma \lambda x. t : \alpha \to \beta$}
  \end{prooftree}
  \begin{prooftree}
    \AxiomC{$\Gamma_l; \Gamma_i \vdash_\Sigma t : \alpha \limp \beta$}
    \AxiomC{$\Delta_l; \Delta_i \vdash_\Sigma u : \alpha$}
    \RightLabel{(l-app)}
    \BinaryInfC{$(\Gamma_l, \Delta_l); (\Gamma_i, \Delta_i) \vdash_\Sigma (t\ u) : \beta$}
  \end{prooftree}
  \begin{prooftree}
    \AxiomC{$\Gamma_l; \Gamma_i \vdash_\Sigma t : \alpha \to \beta$}
    \AxiomC{$\emptyset; \Delta_i \vdash_\Sigma u : \alpha$}
    \RightLabel{(i-app)}
    \BinaryInfC{$\Gamma_l; (\Gamma_i, \Delta_i) \vdash_\Sigma (t\ u) : \beta$}
  \end{prooftree}
  \caption{\label{fig:type-judgments} Type judgment schemas of the
    well-typed lambda terms $\Lambda(\Sigma)$ built on a signature
    $\Sigma = \mathopen{<}A, C, \tau\mathclose{>}$.}
\end{figure}

The definition of a well-typed lambda term already gives us an
interesting combinatorial structure. To make this structure even more
useful, we often focus ourselves only on terms that have a specific
\emph{distinguished type}. Using this notion of a signature of typed
constants and some distinguished type, we can describe languages of,
e.g. tree-like (and by extension string-like), lambda terms.

\subsection{Example Signature}
\label{ssec:example-sig}

Let us take a look at an example from
\cite{pogodalla2007generalizing}. We will start with a very simple
signature of string expressions with the concatenation operator,
$\Sigma_{String} = \mathopen{<}A_{String}, C_{String},
\tau_{String}\mathclose{>}$. Our signature will need only one atomic
type, $A_{String} = \{\textsc{String}\}$. Our constants will be the
wordforms of our example fragment (\emph{every}, \emph{some},
\emph{man}, \emph{woman}, \emph{loves}), the empty string $\epsilon$ and
the string concatenation operator, $+$. $\tau_{String}$ assigns the type
$\textsc{String}$ to all the wordforms and to $\epsilon$, and the type
$\textsc{String} \limp \textsc{String} \limp
\textsc{String}$\footnote{As a convention, whenever we omit parentheses
  in a type, we presume the $\limp$ and $\to$ type constructors always
  bind from the right, meaning that $a \to b \to c$ should be read as $a
  \to (b \to c)$.}  to the concatenation operator $+$.

Now we can look at some well-typed terms from the string domain
(i.e. elements of $\Lambda(\Sigma_{String})$). The term $t_1 =
some\ +\ woman$\footnote{Here we introduce another notational
  convention. The unadorned way of writing this term would be $t_1 =
  (+\ some)\ woman$. First, we will allow ourselves to drop the
  parentheses, meaning that any string of expressions $f\ x\ y$ should
  be read as $(f\ x)\ y$. Second, we will admit a specific infix
  notation for some constants which denote functions of two
  arguments. This will then let us write $x\ +\ y$ instead of
  $+\ x\ y$.} denotes the concatenation of \emph{some} and \emph{woman},
which is the phrase \emph{some\ woman}; its type is $\textsc{String}$. A
term such as $t_2 = \lambda^{\circ} x. x\ +\ man$ denotes a function
that appends the string \emph{man} to its argument; its type is
$\textsc{String} \limp \textsc{String}$. If we restrict the set
$\Lambda(\Sigma_{String})$ only to terms having the distinguished type
$\textsc{String}$, we get the set of expressions which denote strings (a
set that contains terms like $t_1$ but not $t_2$).

\subsection{Lexicons}

The idea of a signature is coupled with the one of \textbf{lexicon},
which is a mapping between two different signatures (mapping the
constants of one into well-typed terms of the other). Formally speaking,
a lexicon $\mathcal{L}$ from a signature $\Sigma_1 = \mathopen{<}A_1,
C_1, \tau_1\mathclose{>}$ (which we call the abstract signature) to a
signature $\Sigma_2 = \mathopen{<}A_2, C_2, \tau_2\mathclose{>}$ (which
we call the object signature) is a pair $\mathopen{<}F, G\mathclose{>}$
such that:

\begin{itemize}
\item $G$ is a mapping from $C_1$ to $\Lambda(\Sigma_2)$ assigning to
  every constant of the abstract signature a term in the object
  signature, which can be understood as its
  interpretation/implementation/realization.
\item $F$ is a mapping from $A_1$ to $\mathcal{T}(A_2)$ which links the
  abstract-level types with the object-level types that they are
  realized as.
\item $F$ and $G$ are compatible, meaning that for any $c \in C_1$, we
  have $\vdash_{\Sigma_2} G(c) : \hat{F}(\tau_1(c))$ (we will be using
  $\hat{F}$ and $\hat{G}$ to refer to the homomorphic extensions of $F$
  and $G$ to $\mathcal{T}(A_1)$ and $\Lambda(\Sigma_1)$
  respectively). This property will be referred to as the
  \emph{homomorphism property} of a lexicon.
\end{itemize}

See Figure~\ref{fig:single-acg} for the kind of diagram we will be using
to represent signatures and lexicons that will form our grammars.

\begin{figure}
  \centering
  \begin{subfigure}[b]{0.4\textwidth}
    \centering
    \includegraphics[height=0.2\textheight]{diagrams/single-acg.pdf}
    \caption{{\label{fig:single-acg} A lexicon with its abstract
        and object signatures.}}
  \end{subfigure}
  \qquad
  \begin{subfigure}[b]{0.4\textwidth}
    \centering
    \includegraphics[height=0.2\textheight]{diagrams/double-acg.pdf}
    \caption{{\label{fig:double-acg} Two lexicons sharing the same
        abstract signature.}}
  \end{subfigure}
  \caption{Diagrams of abstract categorial grammars.}
\end{figure}

An abstract categorial grammar for us will then be just a collection of
signatures with their distinguished types and lexicons connecting these
signatures. A common pattern will have us using two object signatures
for the surface forms of utterances (strings) and their logical forms
(logical propositions) and an abstract signature which is connected to
both of the object signatures via lexicons (as we can see on
Figure~\ref{fig:double-acg}). Parsing is then just a matter of inverting
the surface lexicon to get the abstract term and then applying to it the
logical lexicon. Generation is symmetric, we simply invert the logical
lexicon and apply the surface lexicon.

\subsection{Example Lexicon}
\label{ssec:example-lex}

\newcommand{\synt}[1]{C_{\textrm{#1}}}

To illustrate the ideas of a lexicon and an abstract categorial grammar,
we will expand our example from \ref{ssec:example-sig}. We will
consider another signature, $\Sigma_{Synt}$, which will describe the
syntax of quantified noun phrases in the style of Montague
\cite{montague1973proper}. The atomic types $A_{Synt}$ will consist of
the types $NP$, $N$ and $S$. Our constants, $C_{Synt} = \{\synt{every},
\synt{some}, \synt{love}, \synt{man}, \synt{woman}\}$, will have the
following types, as predicted by $\tau_{Synt}$:

\begin{align*}
\tau_{Synt}(\synt{every}) &= N \limp ((NP \limp S) \limp S) \\
\tau_{Synt}(\synt{some}) &= N \limp ((NP \limp S) \limp S) \\
\tau_{Synt}(\synt{love}) &= NP \limp NP \limp S \\
\tau_{Synt}(\synt{man}) &= N \\
\tau_{Synt}(\synt{woman}) &= N
\end{align*}

Let us explore some terms from $\Lambda(\Sigma_{Synt})$. Let $t_3 =
\synt{some}\ \synt{woman}$, $t_3$ has type $(NP \limp S) \limp S$, which
is the type that serves to describe quantified noun phrases in our
example. Terms of this type expect a verb phrase (or some other
predicate) of type $NP \limp S$, and can yield a sentence of type $S$.

Now we will see how this approach can handle transitive verbs. Let us
consider the term $t_4 = \lambda^{\circ}
x.\ (\synt{some}\ \synt{woman})\ (\lambda^{\circ}
y.\ \synt{love}\ x\ y)$, which has type $NP \limp S$ and represents the
verb phrase \emph{loves some woman}. To build it, we first take the
expression $\synt{love}\ x\ y$ (\emph{$x$ loves $y$}, type $S$) and we
abstract over $y$ to get the predicate $\lambda^{\circ}
y.\ \synt{love}\ x\ y$ (\emph{is loved by $x$}, type $NP \limp S$). By
applying the quantified noun phrase $t_3$ to this term, we get
$(\synt{some}\ \synt{woman})\ (\lambda^{\circ} y.\ \synt{love}\ x\ y)$
(\emph{$x$ loves some woman}, type $S$). Finally, by abstracting over
$x$, we get the verb phrase $t_4$.

$t_5 = (\synt{every}\ \synt{man})\ (\lambda^{\circ}
x.\ (\synt{some}\ \synt{woman})\ (\lambda^{\circ}
y.\ \synt{love}\ x\ y))$ is the result of applying the quantified noun
phrase $\synt{every}\ \synt{man}$ (of type $(NP \limp S) \limp S$) to
$t_4$. What we get is a term of type $S$ which describes the sentence
\emph{every man loves some woman}. Note that as before, we can restrict
the set $\Lambda(\Sigma_{Synt})$ to terms having the distinguished type
$S$ and we will arrive at the set of terms which describe sentences
(this set will include $t_5$, but not $t_3$ or $t_4$).

In the example above, I have been presuming some kind of implied
connection between the terms of $\Lambda(\Sigma_{Synt})$ and English
phrases. Indeed, while we have defined a system of structures which
describe the quantification and predicate structures of a microscopic
fragment of English and a system for talking about strings in
concatenation, we have not given any explicit link between the two. It
is at this moment that we will introduce a lexicon to link these two
levels of description.

Our lexicon $\mathcal{L}_{syntax}$ will map the constants of
$\Sigma_{Synt}$, our abstract signature, into terms from
$\Lambda(\Sigma_{String})$, our object signature. If we view terms of
$\Lambda(\Sigma_{Synt})$ as abstract computations, the lexicon will
instantiate this abstraction by providing an implementation for the
constants of $\Sigma_{Synt}$. This way we can map an abstract
computation representing a phrase into a more specific object
computation which calculates the string representation.

So, how does our lexicon $\mathcal{L}_{syntax}$ look like? It will map
all the atomic types of $\Sigma_{Synt}$ into
$\textsc{String}$.\footnote{Whenever we talk about some lexicon, we will
  use the lexicon itself, which is formally a pair of mappings
  $\mathopen{<}F, G\mathclose{>}$, to mean either $F$, $G$ or their
  homomorphic extensions $\hat{F}$ and $\hat{G}$ depending on whether
  the argument is an atomic type, a constant, a complex type or a term
  respectively.}

\begin{align*}
\mathcal{L}_{syntax}(N) &= \textsc{String} \\
\mathcal{L}_{syntax}(NP) &= \textsc{String} \\
\mathcal{L}_{syntax}(S) &= \textsc{String}
\end{align*}

We can construct the homomorphic extension of the above type mapping
which can give us the object-level interpretations of complex abstract
types, such as the type of predicates, $NP \limp S$, which becomes a
unary string function, $\textsc{String} \limp \textsc{String}$, or the
type of quantified noun phrases, $(NP \limp S) \limp S$, which becomes a
higher-order string function, $(\textsc{String} \limp \textsc{String})
\limp \textsc{String}$.

With the types out of the way, we can give the interpretation of the
individual constants of $\Sigma_{Synt}$.

\begin{align*}
\mathcal{L}_{syntax}(\synt{every}) &= \lambda^{\circ} x R.\ R\ (every\ +\ x) \\
\mathcal{L}_{syntax}(\synt{some}) &= \lambda^{\circ} x R.\ R\ (some\ +\ x) \\
\mathcal{L}_{syntax}(\synt{love}) &= \lambda^{\circ} x y.\ x\ +\ loves\ +\ y \\
\mathcal{L}_{syntax}(\synt{man}) &= man \\
\mathcal{L}_{syntax}(\synt{woman}) &= woman \\
\end{align*}

We can now go back to our examples from $\Lambda(\Sigma_{Synt})$ and
look at what they look like after applying the lexicon to them.

\begin{itemize}
\item $t_3 = \synt{some}\ \synt{woman}$ \\ Mapping this term using the
  lexicon and $\beta$-reducing gives us $\mathcal{L}_{syntax}(t_3)
  =_{\beta} \lambda^{\circ} R.\ R\ (some\ +\ woman)$, which is a
  type-raised version of the string \emph{some woman}.
\item $t_4 = \lambda^{\circ}
  x.\ (\synt{some}\ \synt{woman})\ (\lambda^{\circ}
  y.\ \synt{love}\ x\ y)$ \\ Our verb phrase ends up being mapped onto
  a function which appends the phrase \emph{loves some woman} to its
  argument, $\mathcal{L}_{syntax}(t_4) =_{\beta} \lambda^{\circ}
  x.\ x\ +\ loves\ +\ some\ +\ woman$.
\item $t_5 = (\synt{every}\ \synt{man})\ (\lambda^{\circ}
  x.\ (\synt{some}\ \synt{woman})\ (\lambda^{\circ}
  y.\ \synt{love}\ x\ y))$ \\ Finally, the sentence (type $S$) is mapped
  into a simple $\textsc{String}$, $\mathcal{L}_{syntax}(t_5) =_{\beta}
  every\ +\ man\ +\ loves\ +\ some\ +\ woman$.
\end{itemize}

Now we have enough machinery in play to define the set of strings which
form our fragment of English. We will consider the \emph{abstract
  language} generated by our signature $\Sigma_{Synt}$ and the
distinguished type $S$, that is, elements of $\Lambda(\Sigma_{Synt})$
having type $S$. Then we can define the \emph{object language}, which is
the image of the abstract language when transformed using the
lexicon. The object language contains strings, i.e. terms from
$\Lambda(\Sigma_{String})$ having the type $\textsc{String}$. However,
the object language does not contain all such terms, but only those
object terms, for which there exists a term in the abstract language
such that its image given by the lexicon yields the same object term,
i.e. it contains only terms which denote strings that spell out
sentences of our fragment of English.

\subsection{Example Semantic Lexicon}
\label{ssec:acg-sem}

One perk of working with abstract categorial grammars is that one
abstract term can be interpreted in multiple ways, using different
lexicons. In the previous chapter, we considered the abstract terms of
the $\Sigma_{Synt}$ signature and interpreted them as computations on
strings. Now we will take the same abstract terms, but try to interpret
them as computations on entities and truth values. A diagram of this
setup can be seen on the Figure~\ref{fig:double-acg}.

We will introduce a new signature, $\Sigma_{Sem}$, for our semantic
computations. The atomic types $A_{Sem}$ will consist of a type for
entities, $e$, and a type for truth values, $t$. The constants $C_{Sem}$
will contain the atomic predicates from our fragment, $\textbf{man}$,
$\textbf{woman}$ and $\textbf{love}$, logical connectives, $\Rightarrow$
and $\land$, and quantifiers, $\forall$ and $\exists$. Their types as
given by $\tau_{Sem}$ are as follows:\footnote{The non-linear
  implication ($\to$) in the types of $\forall$ and $\exists$, $(e \to
  t) \limp t$, means that the variable ``introduced'' by the quantifier
  can be used multiple times in the predicate, which has type $e \to
  t$. We will rely on this property later when defining the meanings of
  determiners.}

\begin{align*}
\tau_{Sem}(\textbf{man}) &= e \limp t \\
\tau_{Sem}(\textbf{woman}) &= e \limp t \\
\tau_{Sem}(\textbf{love}) &= e \limp e \limp t \\
\tau_{Sem}(\Rightarrow) &= t \limp t \limp t \\
\tau_{Sem}(\land) &= t \limp t \limp t \\
\tau_{Sem}(\forall) &= (e \to t) \limp t \\
\tau_{Sem}(\exists) &= (e \to t) \limp t
\end{align*}

Now to see how this signature connects to our abstract signature
$\Sigma_{Synt}$, we will give a lexicon from the latter to the
former. First, we give the type mappings. $\mathcal{L}_{sem}(N) = e
\limp t$ meaning that nouns will yield boolean functions of one argument
(unary \emph{predicates} in functional programming
terminology). $\mathcal{L}_{sem}(NP) = e$, simple noun phrases will be
mapped into terms which yield some entity. Finally,
$\mathcal{L}_{sem}(S) = t$, sentences will be assigned terms which
compute their truthiness. Let us see how this plan is achieved in the
$\mathcal{L}_{sem}$ lexicon.\footnote{We will be using $\forall x.\ M$
  as a shortcut for $\forall\ (\lambda x.\ M)$ and $\exists x.\ M$ for
  $\exists\ (\lambda x.\ M)$.}

\begin{align*}
\mathcal{L}_{sem}(\synt{every}) &= \lambda^{\circ} P Q.\ \forall x.\ ((P\ x) \Rightarrow (Q\ x)) \\
\mathcal{L}_{sem}(\synt{some}) &= \lambda^{\circ} P Q.\ \exists x.\ ((P\ x) \land (Q\ x)) \\
\mathcal{L}_{sem}(\synt{love}) &= \lambda^{\circ} so.\ (\textbf{love}\ s\ o) \\
\mathcal{L}_{sem}(\synt{man}) &= \lambda^{\circ} x.\ (\textbf{man}\ x) \\
\mathcal{L}_{sem}(\synt{woman}) &= \lambda^{\circ} x.\ (\textbf{woman}\ x)
\end{align*}

Let us now consider the example terms of the $\Sigma_{Synt}$ signature
from \ref{ssec:example-lex}. $t_3 = \synt{some}\ \synt{woman}$ will be
interpreted as $\mathcal{L}_{sem}(t_3) =_{\beta} \lambda^{\circ}
Q.\ \exists x.\ ((\textbf{woman}\ x) \land (Q\ x))$ having type $(e
\limp t) \limp t$. It is a function that expects some predicate and
tests whether that predicate holds for at least some woman (some entity
for which the $\textbf{woman}$ predicate holds).

When we consider $t_4 = \lambda^{\circ}
x.\ (\synt{some}\ \synt{woman})\ (\lambda^{\circ}
y.\ \synt{love}\ x\ y)$, we get $\mathcal{L}_{sem}(t_4) =_{\beta}
\lambda^{\circ} x.\ \exists y.\ ((\textbf{woman}\ y) \land
(\textbf{love}\ x\ y))$ of type $e \limp t$. What we have here is a
predicate function testing whether the argument entity loves some woman.

Finally, in $t_5 = (\synt{every}\ \synt{man})\ (\lambda^{\circ}
x.\ (\synt{some}\ \synt{woman})\ (\lambda^{\circ}
y.\ \synt{love}\ x\ y))$, we have $\mathcal{L}_{sem}(t_5) =_{\beta}
\forall x.\ ((\textbf{man}\ x) \Rightarrow (\exists
y.\ ((\textbf{woman}\ y) \land (\textbf{love}\ x\ y))))$ of type
$t$. This computation yields a truth value, which tells us whether the
proposition that every man loves some woman is true given some universe
that the quantifiers range over and some values of the $\textbf{man}$,
$\textbf{woman}$ and $\textbf{love}$ predicates. The term itself, in its
$\beta$-normal form, can serve as our semantic representation for the
proposition \emph{every man loves some woman}.

We will finish our exposition of abstract categorial grammars by
highlighting a prominent feature of the example grammar we have just
described and that is its treatment of scope ambiguity. You might have
noticed that $t_5 = (\synt{every}\ \synt{man})\ (\lambda^{\circ}
x.\ (\synt{some}\ \synt{woman})\ (\lambda^{\circ}
y.\ \synt{love}\ x\ y))$ is not the only term in
$\Lambda(\Sigma_{Synt})$ for which $\mathcal{L}_{syntax}(t_5) =_{\beta}
every\ +\ man\ +\ loves\ +\ some\ +\ woman$. We could just as well take
$t_6 = (\synt{some}\ \synt{woman})\ (\lambda^{\circ}
y.\ (\synt{every}\ \synt{man})\ (\lambda^{\circ}
x.\ \synt{love}\ x\ y))$ which is not $\beta$-equivalent to $t_5$. When
we apply our syntactic lexicon to $t_6$, we see that we end up with an
expression denoting the same string, $\mathcal{L}_{syntax}(t_6)
=_{\beta} every\ +\ man\ +\ loves\ +\ some\ +\ woman$.

However, when we consider a different interpretation for the abstract
constants in $\Sigma_{Synt}$, for example our semantic lexicon
$\mathcal{L}_{sem}$, we can see the differences rise to surface.

\begin{align*}
\mathcal{L}_{sem}(t_5) &=_{\beta} \forall x.\ ((\textbf{man}\ x)
\Rightarrow (\exists y.\ ((\textbf{woman}\ y) \land
(\textbf{love}\ x\ y)))) \\
\mathcal{L}_{sem}(t_6) &=_{\beta} \exists y.\ ((\textbf{woman}\ y)
\land (\forall x.\ ((\textbf{man}\ x) \Rightarrow
(\textbf{love}\ x\ y))))
\end{align*}

When we try to parse some sentence using abstract categorial grammars,
we are trying to find the abstract terms which upon transformation by
the lexicon and $\beta$-reduction yield the sentence encoded in some
object term. This is basically trying to invert the lexicon function,
modulo $\beta$-equivalence. It is therefore not surprising then that we
can find multiple abstract terms which all map to the same string term
but which can be mapped to distinct terms using the semantic lexicon. It
is this mechanism that enables abstract categorial grammars to handle
ambiguity. When we reverse the scenario and go from semantic
representations to strings, the same situation can occur (more than one
abstract term having the same semantics but different surface strings)
and this is what enables paraphrases.
