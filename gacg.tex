\chapter{Graphical Abstract Categorial Grammars}
\label{chap:gacg}

In this chapter, we will introduce a generalization of abstract
categorial grammars that gracefully solves the modularity issues that we
saw in the previous chapter.

\section{Intersections of Languages}
\label{sec:sects-of-langs}

Before we proceed to define our extension of ACGs, we will first need to
present the manner in which ACGs and their compositions are formulated
in ACG literature.

\subsection{The Usual Formalization of ACGs}
\label{ssec:usual-acgs}

Let us consider a system with three signatures $\Sigma_1$, $\Sigma_2$
and $\Sigma_3$, their respective distinguished types $S_1$, $S_2$ and
$S_3$ and two lexicons $\mathcal{L}_{12} : \Sigma_1 \to \Sigma_2$ and
$\mathcal{L}_{23} : \Sigma_2 \to \Sigma_3$ such that
$\mathcal{L}_{12}(S_1) = S_2$ and $\mathcal{L}_{23}(S_2) = S_3$. See
Figure~\ref{fig:acg-serial-comp} for a diagrammatic visualization of
this structure.

\begin{figure}[t]
  \centering
  \begin{subfigure}[b]{0.4\textwidth}
    \centering
    \includegraphics[height=0.2\textheight]{diagrams/acg-serial-comp.pdf}
    \caption{\label{fig:acg-serial-comp} Serial composition of ACGs.}
  \end{subfigure}
  \qquad
  \begin{subfigure}[b]{0.4\textwidth}
    \centering
    \includegraphics[height=0.2\textheight]{diagrams/acg-parallel-comp.pdf}
    \caption{\label{fig:acg-parallel-comp} Parallel composition of ACGs.}
  \end{subfigure}
  \caption{\label{fig:acg-comp-modes} Two modes of composition for
    ACGs.}
\end{figure}

We can now define languages $A_1$, $A_2$ and $A_3$ where $A_i$ is the
set of terms from $\Lambda(\Sigma_i)$ that have the type $S_i$. Such
languages, which are defined only in terms of a signature and some
distinguished type, are called \emph{abstract languages} in the
terminology of ACGs. They consist of terms whose structure is
constrained only by the types assigned by the signature.

Further than that, we can look at the languages $\mathcal{L}_{12}(A_1)$
and $\mathcal{L}_{23}(A_2)$, images of the abstract languages given by
the lexicons. Because of the homomorphism property of lexicons, all
elements of $\mathcal{L}_{12}(A_1)$ will have the type
$\mathcal{L}_{12}(S_1) = S_2$ and will therefore also belong to $A_2$
(similarly, we have that $\mathcal{L}_{23}(A_2) \subseteq A_3$). These
new languages, which are formed by mapping an ACG abstract language
using a lexicon, are called \emph{object languages}. Their terms are
constrained not only by the types of the signature they are built upon
but also by the type system of the abstract signature.

Finally, we can also take the composition of lexicons $\mathcal{L}_{13}
= \mathcal{L}_{23} \circ \mathcal{L}_{12}$, which itself is also a
lexicon, and map it over $A_1$. This gives us a language
$\mathcal{L}_{13}(A_1) = \mathcal{L}_{23}(\mathcal{L}_{12}(A_1))$ which
is at the same time the image of the object language
$\mathcal{L}_{12}(A_1)$ given by $\mathcal{L}_{23}$ and also the image
of the abstract language $A_1$ given by $\mathcal{L}_{13}$ (thus it is
itself also an object language). This points to an interesting property
of ACG languages: they are closed under transformation by a lexicon.

In the ACG literature, ACGs are defined as quadruples $\mathcal{G} =
\mathopen{<}\Sigma_A, \Sigma_O, \mathcal{L}, S\mathclose{>}$ where
$\Sigma_A$ is the abstract signature, $\Sigma_O$ is the object
signature, $\mathcal{L} : \Sigma_A \to \Sigma_O$ is a lexicon linking
the two and $S$ is a distinguished type of the abstract signature
$\Sigma_A$. From this grammar, we can define two languages. The abstract
language $\mathcal{A}(\mathcal{G}) = \{t \in \Lambda(\Sigma_A) \mid
\ \vdash_{\Sigma_A} t : S\}$ and the object language
$\mathcal{O}(\mathcal{G}) = \mathcal{L}(\mathcal{A}(\mathcal{G})) = \{t
\in \Lambda(\Sigma_O) \mid \exists u \in \mathcal{A}(\mathcal{G}),
\mathcal{L}(u) = t\}$. The composition of two ACGs $\mathcal{G}_1 =
\mathopen{<}\Sigma_1, \Sigma_2, \mathcal{L}_{12}, S_1\mathclose{>}$ and
$\mathcal{G}_2 = \mathopen{<}\Sigma_2, \Sigma_3, \mathcal{L}_{23},
S_2\mathclose{>}$ is defined as $\mathcal{G}_2 \circ \mathcal{G}_1 =
\mathopen{<}\Sigma_1, \Sigma_3, \mathcal{L}_{23} \circ \mathcal{L}_{12},
S_1\mathclose{>}$.

The definition of ACGs given above is quite practical in that it is
complete, i.e. it gives a precise account of what set of languages are
generated by ACGs (abstract and object languages for which there exist
the quadruples described above). This contrasts with the presentation of
ACGs that we gave in~\ref{sec:acg}, where we defined ACGs as collections
of signatures associated with distinguished types and connected with
lexicons. Our definition only introduced the requisite machinery, but
delayed the delimitation of the way languages can be defined. Leaving
this question open will let us answer it now by providing an extension
of ACGs which will help us overcome the modularity issues that have been
the theme of Chapter~\ref{chap:constraints}.\footnote{Incidentally, this
  was not the reason for the way we presented ACGs in~\ref{sec:acg}. We
  chose this style as it grouped together the information in a more
  natural way. We approach signatures as descriptions of domains
  (strings, syntax, semantics), each one being associated with a
  distinguished type telling us which objects the domain has set out to
  describe (strings, sentences, truth values). Having distinguished
  types directly attached to signatures allows us to omit them from the
  ACG quadruples, $\mathopen{<}\Sigma_A, \Sigma_O, \mathcal{L},
  \cancel{S}\mathclose{>}$. However, this only leaves us with triples
  containing the two signatures and the lexicon connecting them, and
  since we can infer the signatures themselves from the domain and the
  range of the lexicon $\mathcal{L} : \Sigma_A \to \Sigma_O$, we do not
  have much motivation to introduce these tuples,
  $\mathopen{<}\cancel{\Sigma_A}, \cancel{\Sigma_O}, \mathcal{L},
  \cancel{S}\mathclose{>}$. Instead of composing ACGs, we compose just
  the lexicons.

On top of that, we will want to define signatures and lexicons to yield
multiple different object languages (at least one for the string
representations of forms and one for the semantic representations of
meaning), which would mean having at least two different ACGs which are
somehow linked together (e.g. by sharing the same abstract
signature). However, since these two grammars are so interrelated, we
would like to reason about them in a way that makes these relationships
explicit and thus easier to study as opposed to considering a collection
of grammars which are somehow implicitly similar.}

\subsection{Patterns of Composition in ACGs}
\label{ssec:acg-patterns}

Before we turn to our proposal, we will quickly recall some of the other
styles of composition used in ACGs (a more detailed exposition can be
found in \cite{pogodalla2012controlling}). Besides making the object
signature of one grammar be the abstract signature of another as we saw
before (Figure~\ref{fig:acg-serial-comp}), we can have two grammars
share the same abstract signature allowing us to transduce between terms
in the two object signatures (Figure~\ref{fig:acg-parallel-comp}).

NB: \emph{Transduction} is a process in which mapping an object $o_1$ to
(potentially many) other objects $o_2$ is realized by first inverting
one function $f_1$ to find the object's antecedents $a$ and then
applying to them another function $f_2$, i.e. an object $o_1$ is
transduced to an object $o_2$ whenever there exists an $a$ such that
$f_1(a) = o_1$ and $f_2(a) = o_2$. In our example, terms from
$\mathcal{O}( \mathopen{<} \Sigma_1, \Sigma_2, \mathcal{L}_{12}, S
\mathclose{>} )$ are transduced to terms from $\mathcal{O}( \mathopen{<}
\Sigma_1, \Sigma_3, \mathcal{L}_{13}, S \mathclose{>} )$ by inverting
the lexicon $\mathcal{L}_{12}$ to find an antecedent in $\mathcal{A}(
\mathopen{<} \Sigma_1, \Sigma_2, \mathcal{L}_{12}, S \mathclose{>} )$
and then applying to it the lexicon $\mathcal{L}_{13}$.

\begin{figure}[t]
  \centering
  \begin{subfigure}[b]{0.4\textwidth}
    \centering
    \includegraphics[height=0.2\textheight]{diagrams/parallel-over-serial.pdf}
    \caption{\label{fig:parallel-over-serial} Transduction from an
      abstract signature.}
  \end{subfigure}
  \qquad
  \begin{subfigure}[b]{0.4\textwidth}
    \centering
    \includegraphics[height=0.2\textheight]{diagrams/serial-over-parallel.pdf}
    \caption{\label{fig:serial-over-parallel} Constraint on an abstract
      signature.}
  \end{subfigure}
  \caption{\label{fig:acg-comp-patterns} Mixing the ACG modes of
    composition.}
\end{figure}

These two modes of composition can be fruitfully mixed. Consider the
graph on Figure~\ref{fig:parallel-over-serial} in which we introduce a
syntactic signature $Syntax$ where different terms are only allowed to
yield the same string whenever they represent different parses of a
syntactically ambiguous phrase. This means that purely semantic
distinctions such as scope ambiguity have to be moved to a more abstract
signature ($SyntSem$) from whose terms the semantic representation can
be derived by a function ($\mathcal{L}_{interSem}$). This approach is
studied more deeply in \cite{pogodalla2007generalizing}.

Another interesting composition pattern is to take an existing structure
of grammars and add a new abstract signature on top
(Figure~\ref{fig:serial-over-parallel}). This new signature ($Constr$)
can be used to further constrain the items in the previously
abstract-most signature ($Synt$). In \cite{pogodalla2012controlling},
this is what the authors use to develop their constraints on
extraction. Each of their constraints is presented as a new abstract
signature constraining the original syntactic signature.

However, a question that the authors do not pose, but which is of great
interest to us, is how to combine all these constraints. If we were to
apply the same pattern repeatedly to get a structure like the one on
Figure~\ref{fig:stacked-constraints}, we would have to deal with
successively more complex type systems on each level. This is due to the
condition that a lexicon has to be a homomorphism and thus it must,
among other things, always map well-typed terms to well-typed
terms. Because of this, the terms in the abstract language of the
signature we introduce to handle the second constraint must also satisfy
the first constraint, since mapping them by $\mathcal{L}_{constr_2}$
must yield a well-typed term in the signature corresponding to the first
constraint. In the end, whenever we wish to add a new signature to
handle another constraint, we have to acknowledge and reimplement in it
all of the existing constraints. This effectively renders the pattern
useless since we might just as well consider the final abstract-most
signature handling all the constraints ($Constr_{1 \land 2}$) and attach
it directly to the syntactic signature ($Synt$) by taking the
composition of the lexicons in between ($\mathcal{L}_{constr_1} \circ
\mathcal{L}_{constr_2}$).

\begin{figure}[t]
  \centering
  \begin{subfigure}[b]{0.4\textwidth}
    \centering
    \includegraphics[height=0.2\textheight]{diagrams/stacked-constraints.pdf}
    \caption{\label{fig:stacked-constraints} Stacking the constraints
      vertically.}
  \end{subfigure}
  \qquad
  \begin{subfigure}[b]{0.4\textwidth}
    \centering
    \includegraphics[height=0.2\textheight]{diagrams/constraints-side-by-side.pdf}
    \caption{\label{fig:constraints-side-by-side} Laying out the
      constraints side by side.}
  \end{subfigure}
  \caption{Constraining a syntactic signature with multiple
    constraints.}
\end{figure}

What we would like instead is to put the signatures side by side such
that they do not depend on each other
(Figure~\ref{fig:constraints-side-by-side}). However, our language of
syntactic structures is no longer defined by mapping a single abstract
language through a lexicon. It is outside of the scope of the common
formalization of ACGs that we presented in~\ref{ssec:usual-acgs}. How do
we define this language in a manner that is consistent with our current
definitions of ACGs? We can arrive at the answer by examining how the
graphical representations of ACGs are connected to the languages they
define.

\subsection{Interpreting ACG Diagrams}

We will associate a language to every node of an ACG diagram. Before we
begin, we notice that every ACG diagram formed by the above modes of
composition is an arborescence\footnote{An arborescence is a directed
  rooted tree, where every edge points away from the root.} and
therefore every node has at most one predecessor (the parent). To the
root of the tree, the abstract-most signature in the graph, we will
assign the abstract language generated by that signature and its
distinguished type. To all the other nodes, we will assign the result of
mapping their parent's language by the lexicon linking the two. Thanks
to the homomorphism property of the lexicons, we can find distinguished
types for all the non-root nodes. They are simply the images of their
parents' distinguished types by the connecting lexicons. For all of the
nodes, it is true that every term in the language assigned to the node
has the node's distinguished type.

We can confirm that the above graphical model of defining ACGs is
coherent.

First, we can show that our interpretation is sound meaning that any
arborescence adorned with signatures on the nodes, compatible lexicons
on the edges and a distinguished type on the root can only define ACG
languages (abstract or object languages). This is trivial, since the
language corresponding to the root is an ACG abstract language and the
class of ACG languages is closed under transformation by a lexicon and
therefore all of the languages corresponding to the descendants of the
root are ACG languages as well.

Second, we can try and show some kind of completeness. However, there is
not much formalization done to describe a ``system of ACGs that share
some common signatures'' (something that our generalization will
fix). We can nevertheless show that it is possible to express any ACG
using our graphical model. Given a grammar $\mathcal{G} =
\mathopen{<}\Sigma_A, \Sigma_O, \mathcal{L}, S\mathclose{>}$, we just
produce a tree whose root has the signature $\Sigma_A$ and distinguished
type $S$ and which is connected to a single child node having the
signature $\Sigma_O$ by an edge labelled by the lexicon
$\mathcal{L}$. Then the two nodes of our tree define both the abstract
and the object language defined by $\mathcal{G}$. Similarly, we could
argue that the languages we aim to define using ACG diagrams (such as
the ones on Figures \ref{fig:acg-comp-modes} and
\ref{fig:acg-comp-patterns}) are covered by our assignment of languages
to nodes of the diagrams.

We have now given a formal account of how we can read language
definitions from ACG diagrams. Still, we have kept our analysis to the
arborescent diagrams used in current ACG literature, where every node
has at most one parent. We will now proceed to generalize it to cases
where nodes have more than just one parent.

To make the generalization more visible, we will switch from an
algebraic manner of presentation to a relational one. Before, we stated
that the language of a node is the image of its parent's language.

$$
Language(u) = Lexicon(Language(Parent(u)))
$$

Now, we will restate this as saying that the language of a node is the
set of terms that have an antecedent in the parent's language.

$$
Language(u) = \{x \in \Lambda(Signature(u)) \mid \exists a \in
Language(Parent(u)), \; Lexicon(a) = x\}
$$

This definition works for non-root nodes of an ACG diagram. In the root
case, we have to constrain the language by stating that that the terms
of the language must have the root's distinguished type. This is a
property that is also true in the non-root cases due to the homomorphism
property of lexicons. If we wanted to unify the definitions of the root
language and the non-root languages, we would have to check that a term
of the language has the distinguished type and that it has an antecedent
in the parent, if it has any parent. A relational statement of this
unification could look like this.

\begin{align*}
Language(u) = \{&x \in \Lambda(Signature(u)) \mid Type(x) = DistinguishedType(u) \\
&\land \forall p \in Parents(u), \; \exists a \in Language(p), \; Lexicon_{(p,u)}(a) = x\}
\end{align*}

If the node has no parents, no constraint is enforced. If it does have
some, we enforce the antecedent constraint. This shows us a natural
generalization to the case where nodes can have an arbitrary number of
parents. If we transpose this back to the algebraic style of
presentation, we get the following expression.

$$
Language(u) = DistinguishedlyTyped(u) \quad \cap \bigcap_{p \in Parents(u)} Lexicon_{(p,u)}(Language(p))
$$


\section{Definitions}

In this section, we distill the reasoning about generalizing ACG
diagrams to graphs in a definition of an extension for ACGs.

We define a \emph{graphical abstract categorial grammar} as a quadruple
$\mathcal{G} = \mathopen{<} G, \Sigma, S, {\mathcal{L}} \mathclose{>}$
where $G$ is a directed graph with vertices $V(G)$ and edges $E(G)$,
$\Sigma$ and $S$ are labelings assigning signatures and distinguished
types, respectively, to the vertices $V(G)$ and ${\mathcal{L}}$ is a
labeling assigning lexicons to the edges $E(G)$. Furthermore, a
well-formed graphical ACG satisfies the following conditions:

\begin{itemize}
\item $G$ is a directed acyclic graph.
\item For all $(u,v) \in E(G)$, $\mathcal{L}_{(u,v)} : \Sigma_u \to
  \Sigma_v$.
\item For all $(u,v) \in E(G)$, $\mathcal{L}_{(u,v)}(S_u) = S_v$.
\end{itemize}

We will say that a node $u$ is \emph{more abstract} than a node $v$
whenever $(u,v)$ belongs to the strict partial order induced by the
edges of $G$ (i.e. there is a path from $u$ to $v$).

We let the nodes in a graphical ACG $\mathcal{G} = \mathopen{<} G,
\Sigma, S, \mathcal{L} \mathclose{>}$ define two kinds of languages. The
\emph{intrinsic languages} $\mathcal{I}_{\mathcal{G}}$, which are
constrained only by the type signature described in the node itself, and
the \emph{extrinsic languages} $\mathcal{E}_{\mathcal{G}}$, which are
also constrained by type signatures in more abstract nodes of the
graph. These two notions correspond to those of abstract languages and
object languages in ACGs.

$$
\mathcal{I}_{\mathcal{G}}(v) = \{t \in \Lambda(\Sigma_v)
\mid\ \vdash_{\Sigma_v} t : S_v\}
$$
$$
\mathcal{E}_{\mathcal{G}}(v) = \mathcal{I}_{\mathcal{G}}(v) \cap
\bigcap_{(u,v) \in E} \mathcal{L}_{(u,v)}(\mathcal{E}_{\mathcal{G}}(u)).
$$

From the above definition, we see that the ACG diagrams we introduced
before are a special case of graphical ACGs where the graph is an
arborescence.

\section{General Remarks on Graphical ACGs}

In this section, we then examine the key properties and implications of
graphical ACGs.

\subsection{On the Expressivity of Graphical ACGs}

\begin{observation}
  The set of intrinsic languages definable by graphical ACGs is by
  definition the same as the set of abstract languages definable by
  ACGs.
\end{observation}

\begin{theorem}
  The set of extrinsic languages definable by graphical ACGs is the set
  of object languages definable by ACGs closed under intersection and
  transformation by a lexicon.
\end{theorem}

\begin{proof}
  First, we prove that an extrinsic language can be always constructed
  from object languages by intersections and transformations by
  lexicons. Let us consider any graphical ACG $\mathcal{G} =
  \mathopen{<} G, \Sigma, S, \mathcal{L} \mathclose{>}$ and some
  topological ordering $v_1, \ldots, v_n$ of its nodes $V(G)$ (an
  ordering such that more abstract nodes always precede less abstract
  ones). Before we start, we will remark that all the intrinsic
  languages $\mathcal{I}_{\mathcal{G}}(v_i)$ are object languages, since
  intrinsic languages are abstract languages which are in turn just a
  special case of object languages.

  We proceed by induction on the topological ordering:

  \begin{itemize}
    \item For $v_1$, the case is trivial. $v_1$ has no predecessors and
      so $\mathcal{E}_{\mathcal{G}}(v_1) =
      \mathcal{I}_{\mathcal{G}}(v_1)$, which is an object language.
    \item For any other node $v_n$, we look at the definition of
      $\mathcal{E}_{\mathcal{G}}(v_n)$ and remark that the only
      operators are intersection and application of a lexicon with the
      operands being $\mathcal{I}_{\mathcal{G}}(v_n)$ (which is an
      object language) and the extrinsic languages of its predecessors
      (which can be constructed from object languages using
      intersections and lexicons thanks to the induction
      hypothesis). Therefore even $\mathcal{E}_{\mathcal{G}}(v_n)$ can
      be constructed from object languages using only intersections and
      lexicons.
  \end{itemize}


  Now we have to prove the converse. We do so by showing that extrinsic
  languages contain object languages and are closed under intersection
  and transformation by a lexicon.

  \begin{figure}
    \centering
    \begin{subfigure}[b]{0.2\textwidth}
      \centering
      \includegraphics[height=0.3\textheight]{diagrams/proof-object.pdf}
      \caption{\label{fig:proof-object} The case for object languages.}
    \end{subfigure}
    \quad
    \begin{subfigure}[b]{0.4\textwidth}
      \centering
      \includegraphics[height=0.3\textheight]{diagrams/proof-intersection.pdf}
      \caption{\label{fig:proof-intersection} The case for intersections.}
    \end{subfigure}
    \quad
    \begin{subfigure}[b]{0.3\textwidth}
      \centering
      \includegraphics[height=0.3\textheight]{diagrams/proof-lexicon.pdf}
      \caption{\label{fig:proof-lexicon} The case for transformations by
        a lexicon.}
    \end{subfigure}
    \caption{Figures demonstrating that extrinsic languages contain
      object languages closed on transformation by a lexicon and
      intersection.}
  \end{figure}

  \begin{itemize}
    \item Let $L$ be an object language defined by the ACG $\mathcal{G}
      = \mathopen{<} \Sigma_A, \Sigma_O, \mathcal{L},
      S\mathclose{>}$. We take the graph $G$ with $V(G) = \{A, O\}$ and
      $E(G) = \{(A,O)\}$, we label the nodes $A$ and $O$ with $\Sigma_A$
      and $\Sigma_O$ as signatures and $S$ and $\mathcal{L}(S)$ as
      distinguished types respectively . Finally, we label the edge
      $(A,O)$ with $\mathcal{L}$ and we get a graphical ACG $G'$ in
      which $\mathcal{E}_{\mathcal{G'}}(O) = \mathcal{O}(G) = L$
      (Figure~\ref{fig:proof-object}).

    \item Let $L_1$ and $L_2$ be two extrinsic languages defined by the
      nodes $u_1$ and $u_2$ in some graphical ACGs $\mathcal{G}_1$ and
      $\mathcal{G}_2$, respectively. We can construct a new graphical
      ACG $\mathcal{G}'$ by taking the union of the two ACGs (union of
      graphs (union of vertices and edges) and unions of the
      labelings).\footnote{Assuming, without loss of generality, that
        the sets of vertices of the two graphs are disjoint.} We will
      then add a new node $v$ such that $\mathcal{E}_{\mathcal{G}'}(v) =
      L_1 \cap L_2$ (Figure~\ref{fig:proof-intersection}).

      The signature labeling $v$ will be the union of the two signatures
      labeling $u_1$ and $u_2$, ensuring that $\forall u \in \{u_1,
      u_2\}$, $\mathcal{I}_{\mathcal{G}'}(v) \supseteq
      \mathcal{I}_{\mathcal{G}'}(u) \supseteq
      \mathcal{E}_{\mathcal{G}'}(u)$. We can use either of the two
      distinguished types that label $u_1$ or $u_2$ to label $v$ (if
      they are different, then the intersection $L_1 \cap L_2$ is
      trivially empty). Finally, we will add two edges leading from
      $u_1$ and $u_2$ to $v$, both labeled with the identity lexicon. We
      will now show that $\mathcal{E}_{\mathcal{G}'}(v) = L_1 \cap L_2$.

      \begin{align*}
        \mathcal{E}_{\mathcal{G}'}(v) &= \mathcal{I}_{\mathcal{G}'}(v)
        \cap \mathcal{L}_{(u_1,v)}(\mathcal{E}_{\mathcal{G}'}(u_1)) \cap
        \mathcal{L}_{(u_2,v)}(\mathcal{E}_{\mathcal{G}'}(u_2)) \\ &=
        \mathcal{I}_{\mathcal{G}'}(v) \cap
        \mathcal{E}_{\mathcal{G}'}(u_1) \cap
        \mathcal{E}_{\mathcal{G}'}(u_2) \\ &=
        \mathcal{E}_{\mathcal{G}'}(u_1) \cap
        \mathcal{E}_{\mathcal{G}'}(u_2) \\ &=
        \mathcal{E}_{\mathcal{G}_1}(u_1) \cap
        \mathcal{E}_{\mathcal{G}_2}(u_2) \\ &= L_1 \cap L_2
      \end{align*}

      The simplifications use the facts that: the two new lexicons are
      identities, that $\mathcal{I}_{\mathcal{G}'}(v) \supseteq
      \mathcal{E}_{\mathcal{G}'}(u_1) \cap
      \mathcal{E}_{\mathcal{G}'}(u_2)$, that
      $\mathcal{E}_{\mathcal{G}'}(u_1) =
      \mathcal{E}_{\mathcal{G}_1}(u_1)$ and
      $\mathcal{E}_{\mathcal{G}'}(u_2) =
      \mathcal{E}_{\mathcal{G}_2}(u_2)$ and finally that
      $\mathcal{E}_{\mathcal{G}}(u_1) = L_1$ and
      $\mathcal{E}_{\mathcal{G}}(u_2) = L_2$.

  \item Let $L \subseteq \Lambda(\Sigma_O)$ be a language which is the
    result of mapping an extrinsic language $L' \subseteq
    \Lambda(\Sigma_A)$ through the lexicon $\mathcal{L} : \Sigma_A \to
    \Sigma_O$. We will show that $L$ is also an extrinsic language. Let
    $u$ be the node that defines the extrinsic language $L$ in some
    graphical ACG $\mathcal{G}$. We construct a new graphical ACG
    $\mathcal{G}'$ by adding a new vertex $v$ to $\mathcal{G}$ labeled
    with the signature $\Sigma_O$ and the distinguished type
    $\mathcal{L}(S)$ where $S$ is the distinguished type labeling
    $u$. To this graph, we conjoin the edge $(u,v)$ and label it with
    $\mathcal{L}$ (Figure~\ref{fig:proof-lexicon}).

    Now we verify that $\mathcal{E}_{\mathcal{G}'}(v) = L$.

    \begin{align*}
      \mathcal{E}_{\mathcal{G}'}(v) &= \mathcal{I}_{\mathcal{G}'}(v) \cap
      \mathcal{L}(\mathcal{E}_{\mathcal{G}'}(u)) \\
      &= \mathcal{L}(\mathcal{E}_{\mathcal{G}'}(u)) \\
      &= \mathcal{L}(\mathcal{E}_{\mathcal{G}}(u)) \\
      &= \mathcal{L}(L') \\
      &= L
    \end{align*}

    The assumptions used here are in turn: that
    $\mathcal{I}_{\mathcal{G}'}(v) \supseteq
    \mathcal{L}(\mathcal{E}_{\mathcal{G}'}(u))$, that
    $\mathcal{E}_{\mathcal{G}'}(u) = \mathcal{E}_{\mathcal{G}}(u)$, that
    $\mathcal{E}_{\mathcal{G}}(u) = L'$ and that $\mathcal{L}(L') = L$.
  \end{itemize}
\end{proof}

\begin{corollary}
  The set of extrinsic languages definable by graphical ACGs is the same
  as the set of object languages definable by ACGs if and only if the
  set of object languages definable by ACGs is closed under
  intersection.
\end{corollary}

We conclude this subsection with a few words to motivate the need we
feel for this (possibly) more expressive formalism. We believe that in
order to manage the development of wide-coverage grammars, the grammars
need to be kept as simple as possible, which means, among other things,
that independent constraints should be implemented separately and not
complected together (we saw the difficulties caused by this already on a
microscopic fragment in section~\ref{sec:together}). This means that if
we were to define, e.g., a partial grammar in which we would only
enforce agreement and another grammar in which we would only enforce the
proper use of relative pronouns, we would like the language in which
both agreement and proper use of relative pronouns are respected to be
expressible in our formalism, and on top of that, we would like this
language to be easily expressed in terms of the two grammars for the
individual constraints. We now have a requirement on the formalism in
which we would like to use: we want a formalism where the set of all the
``useful'' definable languages is closed on intersection. If the object
languages of ACGs are indeed closed on intersection, then our extension
is just a convenience for expressing intersection more easily. However,
if they are not, we believe our extension adds a critical level of
expressivity needed for simple and modular wide-coverage grammars.


\subsection{On the Decidability of Graphical ACGs}
\label{ssec:graphical-decidability}

We turn to the problem of parsing with graphical ACGs. Parsing with ACGs
is a problem on the limits of decidability. When we consider ACGs whose
abstract signatures only contain types of order 2 or less, parsing is
possible in polynomial time for both linear \cite{salvati2005problemes}
and non-linear \cite{kanazawa2007parsing} type systems (such as the one
we introduced in~\ref{sec:acg}). If the order of the abstract signature
exceeds 2, the membership problem for linear ACGs becomes decidable if
and only if the satisfiability problem in the multiplicative exponential
fragment of linear logic is decidable \cite{de2004vector}, which is an
open problem. On the other hand, by extending the type system to include
dependent types, parsing can become undecidable too since in such a
system type checking itself is undecidable.

Our intent here is to show that by extending the formalism we have not
made the problem of parsing more difficult, at least in terms of
decidability if not in terms of complexity. Let us therefore imagine a
graphical ACG where every edge (two signatures, distinguished types and
a lexicon) is an ACG for which there is an effective parsing algorithm
and type checking is decidable in all the signatures of the graphical
ACG. Then we can prove the existence of a simple effective parsing
algorithm for any of the extrinsic languages defined in the graphical
ACG.

We will be testing whether the term $o$ belongs to
$\mathcal{E}_{\mathcal{G}}(v)$. Our algorithm first checks whether $o$
belongs to $\mathcal{I}_{\mathcal{G}}(v)$ by checking its type. If it
does, it proceeds to verify that it is also in
$\mathcal{E}_{\mathcal{G}}(v)$ by finding antecedents in all of its
abstract predecessors $u_i$, if there are any. We can use the
presupposed parsing algorithm for the ACG $\mathopen{<} \Sigma_{u_i},
\Sigma_v, \mathcal{L}_{(u_i,v)}, S_{u_i}\mathclose{>}$ to find all the
abstract terms $\alpha_{i,j}$ having type $S_{u_i}$ and being
antecedents to $o$ w.r.t. the lexicon $\mathcal{L}_{(u_i,v)}$. Such
terms belong to $\mathcal{I}_{\mathcal{G}}(u_i)$, but in order to prove
that $o$ is in $\mathcal{E}_{\mathcal{G}}(v)$, we need to find an
antecedent that belongs to $\mathcal{E}_{\mathcal{G}}(u_i)$. What we do
is we recursively apply our parsing algorithm to all of the
antecedent-candidates $\{\alpha_{i,j} \mid \forall j\}$ until we find
one which belongs $\mathcal{E}_{\mathcal{G}}(u_i)$. Since the graph is
acyclic, we are guaranteed that this recursive traversal will
terminate. We repeat this for all the predecessors $u_i$ and if we
succeed to find antecedents in all of their extrinsic languages, we have
confirmed the membership of $o$ in $\mathcal{E}_{\mathcal{G}}(v)$ and
also built its abstract antecedent(s).


\subsection{On Grammar Engineering with Graphical ACGs}
\label{ssec:graphical-engineering}

Having covered some of the formal properties of graphical ACGs, we will
get back to building grammars. Armed with this formalism, we can solve
the puzzle of incorporating the three constraints of sections
\ref{sec:negation}, \ref{sec:extraction} and \ref{sec:agreement}. Our
graph $G$ will consist of 6 nodes, $V(G) = \{Neg, Ext, Agr, Synt, Str,
Sem\}$ with edges going from $Neg$, $Ext$ and $Agr$ to $Synt$ and from
$Synt$ to $Str$ and $Sem$ (see Figure~\ref{fig:puzzle-solution}). The
signatures and distinguished types for the first three vertices are
exactly those that have been presented in the first three sections of
Chapter~\ref{chap:constraints}. The lexicons for the edges connecting
these constraint nodes to $Synt$ all behave according to the scheme
below:

\begin{align*}
  \mathcal{L}_{(constraint,Synt)}(X_{constant_{index}}) &= C_{constant} \\
  \mathcal{L}_{(constraint,Synt)}(TYPE\_FEATURES)  &= TYPE
\end{align*}

The $\{Synt, Str, Sem\}$ subgraph is identical to the pair of ACGs
described in \ref{sec:acg} except for some additions that need to be
made so that the fragment covers the wordforms that we have introduced
in the course of discussing the three constraints (prepositions,
relative pronouns, the negative particle $ne$\ldots). However, the types
of these new constants will not be tied to any of those constraints.

\begin{align*}
  C_{de} &: NP \limp N \limp N \\
  C_{qui} &: (NP \limp S) \limp N \limp N \\
  C_{dit\ que} &: NP \limp S \limp S \\
  C_{dorment} &: NP \limp S \\
  C_{ne_{tv}} &: (NP \limp NP \limp S) \limp (NP \limp NP \limp S) \\
  C_{ne_{iv}} &: (NP \limp S) \limp (NP \limp S) \\
  C_{ne_{cv}} &: (NP \limp S \limp S) \limp (NP \limp S \limp S)
\end{align*}

This approach lets us describe the high-level combinatorics of language
that are of interest to the categorial grammarian in a manner which is
idiomatic in academic literature (using the simple and focused types
$N$, $NP$ and $S$). At the same time, we can actually use this textbook
grammar as a basis for a more realistic grammar which handles
constraints such as agreement and extraction islands. Furthermore, these
additional constraints are also defined in a manner that has its
precedent in existing research. When the authors of
\cite{pogodalla2012controlling} decided to put the constraints of
extraction under a microscope and try to encode them in ACGs, they
defined their constraints in exactly the same way as our architecture
does. This graphical architecture lets us write the syntactic kernel and
the additional constraints independently and using two different styles
that have both been shown useful by their own merits, which we see as
indicative of enabling good modularity.

\begin{figure}[t]
  \centering
  \begin{subfigure}[b]{0.4\textwidth}
    \centering
    \includegraphics[height=0.2\textheight]{diagrams/puzzle-solution.pdf}
    \caption{{\label{fig:puzzle-solution} The graph of a grammar
        enforcing all of the constraints discussed in
        Chapter~\ref{chap:constraints}.}}
  \end{subfigure}
  \qquad
  \begin{subfigure}[b]{0.4\textwidth}
    \centering
    \includegraphics[height=0.2\textheight]{diagrams/both-patterns.pdf}
    \caption{{\label{fig:both-patterns} Combining the two ACG patterns
        from~\ref{ssec:acg-patterns} in a single graphical ACG.}}
  \end{subfigure}
  \caption{Practical architectures for graphical ACGs.}
\end{figure}

In the above approach, we have defined a language by writing a grammar
which provides us with useful structures but which does not enforce
complete correctness. We have then refined this grammar by tacking on
constraints ``on the side''. This approach is generally useful and can
be seen, e.g., in \cite{van2004concepts} to define the formal
programming language kernel on which a formal semantics is
established. In our case, we are interested in having intelligible
syntactic structures too as we would like to compute their semantic
representations. The syntax-semantics interface already presents a
significant challenge and having less-than-ideal syntactic structures to
start with does not make formalizing it any easier.

We will show one more persuasive scenario whose goal is to show the
importance of graphical ACGs for having a clean syntax-semantics
interface. In \ref{ssec:acg-patterns}, we have seen an ACG pattern that
put semantic ambiguities into an abstract signature that is higher than
syntax. But there was also another pattern, that of adding a new
abstract signature to constrain syntactic terms. We can combine both of
them in graphical ACGs by superposing their two graphs to get the
structure we can see on Figure~\ref{fig:both-patterns}.

If we try to reap the benefits of both patterns and try to replicate the
same in classical ACGs (arborescent graphs), we hit a snag: we cannot
have both the $Constr$ and $SyntSem$ nodes as the direct predecessors of
the $Syntax$ node. We can make $Constr$ be the predecessor of $Syntax$,
but then $SyntSem$ will be connecting $Constr$ and $Sem$ and the
syntax-semantics interface will have to deal with the types which were
needed to implement syntactic constraints and have no place in a
syntax-semantics interface. If we try it the other way, it is not much
better. $Constr$ will end up having to work with the more complicated
type system of $SyntSem$ instead of being able to talk only about the
$Syntax$ it is interested in.

By putting the constraining signature in a part of the graph unreachable
from the syntax-semantics transducer, we can shield the syntax-semantics
interface from the gnarly implementation details of the rules of
syntax. This in turn gives us a guideline as to what information should
be expressed in the syntactic signature itself and which should be
hidden in constraints: the syntactic signature should only contain
information relevant to the syntax-semantics interface.

This might then raise a question whether the chosen syntactic signature
will end up being suitable for expressing all of the syntactic
constraints. However, this can be resolved by deepening the constraint
subgraph and adding a ``compatibility layer'' in the form of a new
signature which provides different syntactic structures and maps them to
the canonical ones. Constraints can then opt in to controlling the
syntactic structures offered by this new signature.


\section{On Alternative Interpretations of Graphical ACGs}

Our definitions of intrinsic and extrinsic languages have consequences
which might be counter-intuitive and not correspond to the grammarian's
intent. We will describe what these consequences are and propose an
alternative notion of a graphical ACG language which aims to reconcile
them.

The first phenomenon that deserves pointing out occurs whenever two
paths from nodes $u_1$ and $u_2$ converge on a single node $v$. If we
then take a term $\alpha$ from $\mathcal{E}_{\mathcal{G}}(u_1)$, the
term $\beta = \mathcal{L}_{(u_1,v)}(\alpha)$ belongs to
$\mathcal{I}_{\mathcal{G}}(v)$ but not necessarily to
$\mathcal{E}_{\mathcal{G}}(v)$ since it might be the case that there is
no antecedent for $\beta$ in $\mathcal{E}_{\mathcal{G}}(u_2)$. In other
words, mapping a member of $\mathcal{E}_{\mathcal{G}}(u)$ using the
lexicon $\mathcal{L}_{(u,v)}$ does not guarantee that the result belongs
to $\mathcal{E}_{\mathcal{G}}(v)$, which is a different behavior from
that of object languages in ACGs (or that of extrinsic languages in
arborescent graphical ACGs).

This highlights some limitations of our notion of an extrinsic
language. Consider once more the graphical ACG of
Figure~\ref{fig:both-patterns}. We have more than one path converging to
$Syntax$. We will consider a term $\alpha$ of
$\mathcal{E}_{\mathcal{G}}(Sem)$. $\alpha$ has an antecedent in
$\mathcal{E}_{\mathcal{G}}(SyntSem)$ which has a descendant $\beta$ in
$\mathcal{I}_{\mathcal{G}}(Syntax)$. However, because of the constraint
$Constr$ on $Syntax$, $\beta$ can be a syntactic term outside of
$\mathcal{E}_{\mathcal{G}}(Syntax)$ and yielding an ungrammatical
sentence. The notion of an extrinsic language is insufficient to express
the set of meanings from $\Lambda(\Sigma_{Sem})$ which are expressible
only by grammatical sentences. Defining languages like this would be of
particular interest in cases like the one in
Figure~\ref{fig:transducer-grammar} where we have a chain of signatures
representing the different levels of linguistic description whose terms
are in many-to-many relationships expressed through transducers. In such
a scenario, it would be desirable to be able to express the set of
descriptions belonging to one level, e.g. morphology, that correspond to
valid descriptions on all the other levels.

\begin{figure}[t]
  \centering
  \begin{subfigure}[b]{0.4\textwidth}
    \centering
    \includegraphics[width=\textwidth]{diagrams/transducer-grammar.pdf}
    \caption{{\label{fig:transducer-grammar} A graphical ACG connecting
        (constrained) levels of linguistic description through
        transducers.}}
  \end{subfigure}
  \qquad
  \begin{subfigure}[b]{0.4\textwidth}
    \centering
    \includegraphics[height=0.2\textheight]{diagrams/diamond-grammar.pdf}
    \caption{{\label{fig:diamond-grammar} A graphical ACG demonstrating
        two different paths between two nodes.}}
  \end{subfigure}
  \caption{Graphical ACGs posing challenges to extrinsic languages.}
\end{figure}

Compared to ACG object languages (or to extrinsic languages of
arborescent graphical ACGs), we lose another guarantee. In
arborescences, the central role of the root abstract-most signature
guarantees us that whenever a term belongs to an extrinsic language, we
can find terms in all the other extrinsic languages that share the same
abstract-most term. On the other hand, in non-arborescent graphical
ACGs, having a term in an extrinsic language of some node $v$ only
guarantees the presence of corresponding terms in the extrinsic
languages of its ancestors and the intrinsic languages of their
descendants.

The second puzzling scenario is the diamond shape on
Figure~\ref{fig:diamond-grammar}. If we consider a term $\delta$ of
$\mathcal{E}_{\mathcal{G}}(Bottom)$, we know that there exist
antecedents $\beta$ and $\gamma$ in $\mathcal{E}_{\mathcal{G}}(Left)$
and $\mathcal{E}_{\mathcal{G}}(Right)$. And while there definitely exist
antecedents $\alpha$ and $\alpha'$ to both $\beta$ and $\gamma$ in
$\mathcal{E}_{\mathcal{G}}(Top)$, these antecedents can be different,
meaning there does not have to be a single $\alpha \in
\mathcal{E}_{\mathcal{G}}(Top)$ which yields $\beta \in
\mathcal{E}_{\mathcal{G}}(Left)$ and $\gamma \in
\mathcal{E}_{\mathcal{G}}(Right)$ such that they both yield
$\delta$. This means that the result of parsing a term in some
$\mathcal{E}_{\mathcal{G}}(v)$ is a collection of abstract terms with
one term not just per every node $u$ that is more abstract than $v$ but
per every different path leading to $v$. Parsing a term $\delta \in
\mathcal{E}_{\mathcal{G}}(Bottom)$ in our diamond grammar would thus
produce four antecedents $\beta$, $\gamma$, $\alpha$ and $\alpha'$
corresponding to the four paths $[Left,Bottom]$, $[Right,Bottom]$,
$[Top,Left,Bottom]$ and $[Top,Right,Bottom]$, respectively. We contrast
this again with the case of classical ACGs where the result of parsing
can always be represented by associating a term to every node of the
arborescence.\footnote{One could also say that the result of parsing in
  an ACG is just the antecedent in the abstract-most signature and that
  the other terms can then be easily computed by application of
  lexicons. Similarly, we could say that the result of parsing in a
  general graphical ACG is a collection of abstract terms for every
  \emph{maximal} path leading to the node defining the language in
  question. What might be more intuitive, though, is to have some theory
  of graphical ACGs where the result of parsing is a collection of
  antecedents in all the abstract-most nodes.}

We will propose a new way of assigning languages to nodes in a graphical
ACG that will conserve the intuitive properties of ACGs we talked about
above. We do not need to modify the definition of a graphical ACG in
order to do so since the definition is only concerned with the structure
of the graph and its decoration with ACG paraphernalia, not the
languages defined. We will define a third kind of languages based on
graphical ACGs.

Let $\mathcal{G} = \mathopen{<} G, \Sigma, S, \mathcal{L} \mathclose{>}$
be a graphical ACG. We define the \emph{pangraphical language} of node
$u$, $\mathcal{P}_{\mathcal{G}}(u)$, to be the set of terms $t$ such
that there exists a labeling of nodes with terms $T$ satisfying the
following conditions:

\begin{itemize}
  \item $T_u = t$.
  \item For all $v \in V(G)$, $\vdash_{\Sigma_v} T_v : S_v$.
  \item For all $(v,w) \in E(G)$, $\mathcal{L}_{(v,w)}(T_v) = T_w$.
\end{itemize}

It is easy to see that the newly introduced pangraphical languages solve
all of the counter-intuitive quirks of object languages that we
discussed in this subsection.

\begin{itemize}
\item Applying the lexicon $\mathcal{L}_{(u,v)}$ to an element of
  $\mathcal{P}_{\mathcal{G}}(u)$ always yields an element of
  $\mathcal{P}_{\mathcal{G}}(v)$, since the labeling of nodes with terms
  $T$ that proved the former term's membership in the former language
  also proves the latter term's membership in the latter language.

  This definition allows us to directly establish the language of
  meanings which are expressible only by grammatical sentences in
  Figure~\ref{fig:both-patterns} and the language of morphological terms
  that have valid corresponding representations on all the other levels
  of linguistic description in Figure~\ref{fig:transducer-grammar}.
\item The diamond grammar of Figure~\ref{fig:diamond-grammar} is also no
  longer problematic since the labeling of nodes with terms guarantees
  that there is always a single term per node that can generate the term
  being parsed.
\end{itemize}

In the previous section, we took a stab at formalizing ACG diagrams and
finding the simplest extension capable of handling non-arborescent
graphs. The notion of extrinsic languages that we arrived at allowed us
to define a nicely delimited set of languages, the object languages of
ACGs with intersection. Discrepancies in the behavior of extrinsic
languages in arborescent and non-arborescent graphs led us to
pangraphical languages, which behave more in line with our
intuitions. However, the expressivity of pangraphical languages,
especially w.r.t. to extrinsic languages, still remains to be
explored. Due to limitations of both space and time, we will cover the
interesting properties of pangraphical languages only briefly and
partially here.

\begin{description}
  \item[Extrinsic languages can be defined similarly to pangraphical
    languages] \hfill \\

    In the definition of $\mathcal{P}_{\mathcal{G}}(u)$, we replace the
    labeling of nodes with terms by a labeling of all the paths leading
    to $u$.

  \item[$\mathcal{P}_{\mathcal{G}}(u) \subseteq
    \mathcal{E}_{\mathcal{G}}(u) \subseteq
    \mathcal{I}_{\mathcal{G}}(u)$] \hfill \\

    Given a labeling of nodes with terms such that it satisfies the
    conditions in the definition of a pangraphical language, we can show
    by induction on the topological ordering of the graph that every
    term assigned by the labeling belongs to the extrinsic language of
    the same node. Therefore, $\alpha \in \mathcal{P}_{\mathcal{G}}(u)
    \implies \alpha \in \mathcal{E}_{\mathcal{G}}(u)$.

    $\mathcal{E}_{\mathcal{G}}(u) \subseteq
    \mathcal{I}_{\mathcal{G}}(u)$ comes straight from the definition of
    $\mathcal{E}_{\mathcal{G}}(u)$.

    We have thus came up with a series of successively more constrained
    languages: intrinsic languages are constrained by one node,
    extrinsic languages are also constrained by its ancestors and
    pangraphical languages are constrained by the entire graph.

  \item[On arborescences, $\mathcal{P}_{\mathcal{G}}(u) =
    \mathcal{E}_{\mathcal{G}}(u)$.] \hfill \\

    On an arborescence, being a member of an extrinsic language means
    there exists an antecedent in the abstract-most language of the
    arborescence. By virtue of the one-parent property of arborescences,
    we can simply apply all the lexicons in the arborescence to this
    abstract-most antecedent to find a labeling of nodes with terms
    which proves that the member of the extrinsic language is also a
    member of the pangraphical language.

    This confirms that both extrinsic languages and pangraphical
    languages are reasonable generalizations of ACG diagrams since their
    behaviors on arborescences are consistent with each other and with
    that of ACG object languages.

  \item[The set of extrinsic languages is included in the set of
    pangraphical languages.] \hfill \\

    Let us have some node $u$ in a graphical ACG $\mathcal{G}$. We build
    a graphical ACG $\mathcal{G}'$ where every node corresponds to a
    path in $\mathcal{G}$ which ends at $u$ and two nodes are connected
    with an edge whenever one path is an immediate extension of the
    other. We then have $\mathcal{P}_{\mathcal{G'}}([u]) =
    \mathcal{E}_{\mathcal{G}}(u)$.

  \item[Is the set of pangraphical languages included in the set of
    extrinsic languages?] \hfill \\

    That is an interesting question indeed, one whose resolution is left
    as a possible avenue for future work.
\end{description}
